{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from cellmates.data.sample import Sample\n",
    "from cellmates.data.dataset import CellMatesDataset\n",
    "from cellmates.data.stubs import (\n",
    "    generate_dataset_for_n_cells_test, \n",
    "    generate_dataset_for_cell_type, \n",
    "    generate_dataset_for_distances\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Sample(\n",
    "    cell_types=[1,2,3], \n",
    "    distances=torch.zeros((3,3)), \n",
    "    responder_cell_type=1, \n",
    "    is_dividing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1: Padding shouldn't affect the prediction of a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6690],\n",
       "        [3.3507]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6690],\n",
       "        [1.6744]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cellmates.data.stubs import repeated_cell_sample\n",
    "from cellmates.data import CellMatesDataset, collate_fn\n",
    "from cellmates.model.transformer import CellMatesTransformer\n",
    "\n",
    "\n",
    "def test_samples_are_independent_wrt_n_cells():\n",
    "\n",
    "    tr = CellMatesTransformer(D=512, K=int(512/16), num_encoder_layers=0).eval()\n",
    "\n",
    "    b1 = collate_fn([repeated_cell_sample(n) for n in [2, 10]])\n",
    "    b2 = collate_fn([repeated_cell_sample(n) for n in [2, 5]])\n",
    "\n",
    "\n",
    "    o1 = tr(\n",
    "        cell_types_BL=b1['cell_types_BL'], \n",
    "        distances_BLL=b1['distances_BLL'],\n",
    "        padding_mask_BL=b1['padding_mask_BL']\n",
    "    )\n",
    "\n",
    "    o2 = tr(\n",
    "        cell_types_BL=b2['cell_types_BL'], \n",
    "        distances_BLL=b2['distances_BLL'],\n",
    "        padding_mask_BL=b2['padding_mask_BL']\n",
    "    )\n",
    "\n",
    "\n",
    "    display(o1)\n",
    "    display(o2)\n",
    "\n",
    "    assert torch.allclose(o1[0], o2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_cell_sample(10).distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_CELL_TYPE = -1\n",
    "\n",
    "class AddClassificationCellSample:\n",
    "    def __init__(self, sample: Sample) -> None:\n",
    "        self.cell_types = self._cell_types(sample)\n",
    "        self.distances = self._distances(sample)\n",
    "        self.responder_cell_type = sample.responder_cell_type\n",
    "        self.is_dividing = sample.is_dividing\n",
    "        self.L = len(sample.cell_types)\n",
    "\n",
    "    def _cell_types(self, sample: Sample) -> np.ndarray:\n",
    "        return np.concatenate([[SPECIAL_CELL_TYPE], sample.cell_types])\n",
    "    \n",
    "    def _distances(self, sample: Sample) -> np.ndarray:\n",
    "        L = sample.distances.shape[0]\n",
    "        distances = np.zeros((L+1, L+1))\n",
    "        distances[1:, 1:] = sample.distances\n",
    "        return distances\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15]), tensor([0]), tensor([2]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmates.model.transformer import bucketize_distances, N_DISTANCES\n",
    "\n",
    "bucketize_distances(torch.tensor([-1])), bucketize_distances(torch.tensor([0])), bucketize_distances(torch.tensor([20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_DISTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vanilla_einsum():\n",
    "\n",
    "    B,L,H,K = 2,3,5,7   \n",
    "\n",
    "    Q_BLHK = torch.randn((B,L,H,K))\n",
    "    K_BLHK = torch.randn((B,L,H,K))\n",
    "\n",
    "    Q_BHLK = Q_BLHK.permute(0,2,1,3)\n",
    "    K_BHLK = K_BLHK.permute(0,2,1,3)\n",
    "\n",
    "    slow_o = torch.zeros((B,H,L,L))\n",
    "    for sample in range(B):\n",
    "        for head in range(H):\n",
    "            for q in range(L):\n",
    "                for k in range(L):\n",
    "                    slow_o[sample, head, q,k] = torch.dot(Q_BHLK[sample, head, q], K_BHLK[sample, head, k])\n",
    "\n",
    "    fast_o = torch.einsum(\"BLHK,BXHK->BHLX\", Q_BLHK, K_BLHK)\n",
    "\n",
    "    assert torch.allclose(slow_o, fast_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellmates.data.breast import get_datasets\n",
    "\n",
    "ds = get_datasets('F', 100, concatenated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=1024, shuffle=True, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 343])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = next(iter(dl))\n",
    "b1['cell_types_BL'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,H,L,K = 2,3,5,7\n",
    "\n",
    "padding_BL = torch.tensor([\n",
    "    [1,1,0,0,0],\n",
    "    [1,1,1,1,1]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv1 = pd.read_csv('../1.csv')\n",
    "csv2 = pd.read_csv('../2.csv')\n",
    "\n",
    "np.allclose(csv1, csv2, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4414,  0.4792, -0.1353],\n",
       "        [ 0.5304, -0.1265,  0.1165],\n",
       "        [-0.2811,  0.3391,  0.5090]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1: torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [2., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1 @ W: torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4414,  0.5304, -0.2811],\n",
       "        [ 0.8828,  1.0607, -0.5622]], grad_fn=<MmBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1: torch.Size([2, 5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.]],\n",
       "\n",
       "        [[2., 0., 0.],\n",
       "         [2., 0., 0.],\n",
       "         [2., 0., 0.],\n",
       "         [2., 0., 0.],\n",
       "         [2., 0., 0.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1 @ W: torch.Size([2, 5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8828,  1.0607, -0.5622],\n",
       "         [ 0.4414,  0.5304, -0.2811],\n",
       "         [ 0.4414,  0.5304, -0.2811],\n",
       "         [ 0.4414,  0.5304, -0.2811],\n",
       "         [ 0.4414,  0.5304, -0.2811]],\n",
       "\n",
       "        [[ 0.8828,  1.0607, -0.5622],\n",
       "         [ 0.8828,  1.0607, -0.5622],\n",
       "         [ 0.8828,  1.0607, -0.5622],\n",
       "         [ 0.8828,  1.0607, -0.5622],\n",
       "         [ 0.8828,  1.0607, -0.5622]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "torch.manual_seed(42)\n",
    "\n",
    "D = 3\n",
    "L = 5\n",
    "B = 2\n",
    "\n",
    "lin = nn.Linear(D,D, bias=False)\n",
    "\n",
    "display(list(lin.parameters())[0])\n",
    "\n",
    "m1 = torch.zeros((B,D))\n",
    "m1[0,0] = 1\n",
    "m1[1,0] = 2\n",
    "\n",
    "print(f'm1: {m1.shape}')\n",
    "display(m1)\n",
    "\n",
    "print(f'm1 @ W: {lin(m1).shape}')\n",
    "display(lin(m1))\n",
    "\n",
    "\n",
    "m1 = m1.unsqueeze(dim=1).repeat(1,L,1)\n",
    "m1[0,0,0] = 2\n",
    "\n",
    "print(f'm1: {m1.shape}')\n",
    "display(m1)\n",
    "\n",
    "print(f'm1 @ W: {lin(m1).shape}')\n",
    "lin(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1479],\n",
       "         [0.6237]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.1397],\n",
       "         [0.5513]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1, o2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cellmates.data.dataset.CellMatesDataset at 0x13d98a110>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_dataset_for_n_cells_test()\n",
    "generate_dataset_for_cell_type()\n",
    "generate_dataset_for_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = (3.14*(140**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,L,K = 2,3,4\n",
    "\n",
    "E_HLL = torch.randn((H,L,L))\n",
    "\n",
    "V1_LK = torch.randn((L,K))\n",
    "V2_LK = torch.randn((L,K))\n",
    "\n",
    "V_HLK = torch.stack([V1_LK,V2_LK])\n",
    "\n",
    "# using einsum\n",
    "V_LHK = V_HLK.permute(1,0,2)\n",
    "Z_LHK = torch.einsum(\"HLX,XHK->LHK\", E_HLL, V_LHK)\n",
    "\n",
    "# using straightforward:\n",
    "Z_HLK_sf = torch.matmul(E_HLL, V_HLK)\n",
    "Z_HLK_sf = Z_HLK_sf.view(L,H,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.4113, -0.0669, -0.8160, -3.3525],\n",
       "         [ 3.7275,  0.8368,  1.2183,  1.2031]],\n",
       "\n",
       "        [[ 2.6401, -0.3938, -0.3007,  1.2835],\n",
       "         [-2.6774, -0.2836, -1.9936, -1.0862]],\n",
       "\n",
       "        [[ 1.6987, -1.6065, -0.0619,  2.3682],\n",
       "         [ 1.0618,  2.3300,  0.4523, -0.8643]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_LHK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.4113, -0.0669, -0.8160, -3.3525],\n",
       "         [ 2.6401, -0.3938, -0.3007,  1.2835]],\n",
       "\n",
       "        [[ 1.6987, -1.6065, -0.0619,  2.3682],\n",
       "         [ 3.7275,  0.8368,  1.2183,  1.2031]],\n",
       "\n",
       "        [[-2.6774, -0.2836, -1.9936, -1.0862],\n",
       "         [ 1.0618,  2.3300,  0.4523, -0.8643]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_HLK_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellmates.model.transformer import SpatialMultiHeadAttention, CellMatesTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,L,K = 2,3,4\n",
    "D = H*K\n",
    "\n",
    "smh = SpatialMultiHeadAttention(D,H,K,'cpu')\n",
    "tf = CellMatesTransformer(D,H,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 16\n",
    "x = torch.randn((B,L,D))\n",
    "\n",
    "\n",
    "distance_idxs_BLL = torch.randint(low=0, high=10, size=(B,L,L))\n",
    "distance_embeddings = tf.distance_embeddings\n",
    "\n",
    "smh(x, distance_idxs_BLL, distance_embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_types_BL = torch.randint(low=0, high=5, size=(B,L))\n",
    "distance_idxs_BLL = torch.randint(low=0, high=10, size=(B,L,L))\n",
    "\n",
    "tf(cell_types_BL, distance_idxs_BLL).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = CellMatesTransformer(D,H,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.randn((L,D))\n",
    "Wq = torch.randn((D,K))\n",
    "A = torch.randn((L,L,K))\n",
    "\n",
    "E = torch.zeros((L,L))\n",
    "\n",
    "for i in range(L):\n",
    "    for j in range(L):\n",
    "        E[i,j] = (V[i,:] @ Wq) @ A[i,j]\n",
    "\n",
    "\n",
    "E_einsum = torch.einsum('LK,LXK -> LX', V@Wq, A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.randn((L,D))\n",
    "Wq = torch.randn((D,K))\n",
    "A = torch.randn((L,L,K))\n",
    "\n",
    "E = torch.zeros((L,L))\n",
    "\n",
    "for i in range(L):\n",
    "    for j in range(L):\n",
    "        E[i,j] = (V[i,:] @ Wq) @ A[i,j]\n",
    "\n",
    "\n",
    "E_einsum = torch.einsum('LK,LXK -> LX', V@Wq, A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8700,  3.8456, -0.8910],\n",
       "        [ 1.3790, -6.7893, -5.1333],\n",
       "        [ 2.3019,  1.3572, -0.9927]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8700,  3.8456, -0.8910],\n",
       "        [ 1.3790, -6.7893, -5.1333],\n",
       "        [ 2.3019,  1.3572, -0.9927]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4611, -0.4611, -0.4611],\n",
       "         [-0.6132, -0.6132, -0.6132],\n",
       "         [ 0.5478,  0.5478,  0.5478]],\n",
       "\n",
       "        [[-0.9738, -0.9738, -0.9738],\n",
       "         [-1.4068, -1.4068, -1.4068],\n",
       "         [-0.5524, -0.5524, -0.5524]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eqr_BHL = torch.randn((H,L))\n",
    "\n",
    "Eqr_BHL.unsqueeze(-1).expand((H, L, L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9296,  1.5269,  0.1034,  0.4090],\n",
       "         [ 1.0287, -0.4787,  0.0894, -0.8882],\n",
       "         [-0.2348, -0.3270, -0.5398, -1.3754]],\n",
       "\n",
       "        [[ 1.9296,  1.5269,  0.1034,  0.4090],\n",
       "         [ 1.0287, -0.4787,  0.0894, -0.8882],\n",
       "         [-0.2348, -0.3270, -0.5398, -1.3754]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zqr_BLK = torch.randn((2,3,4))\n",
    "\n",
    "Zqr_BLK.unsqueeze(1).expand(size=(2,2,3,4))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]), 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[i,j].shape, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8]), 8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[i,:].shape, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = torch.LongTensor([[1,2,4],[1,2,3]])\n",
    "\n",
    "tf.distance_embeddings['K_qr'](idxs).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
