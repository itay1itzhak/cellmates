{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from cellmates.data.sample import Sample\n",
    "from cellmates.data.dataset import CellMatesDataset\n",
    "from cellmates.data.stubs import (\n",
    "    generate_dataset_for_n_cells_test, \n",
    "    generate_dataset_for_cell_type, \n",
    "    generate_dataset_for_distances\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        responder_cell_type: 1\n",
       "        is_dividing: False\n",
       "        cell_types: [1, 2, 3]\n",
       "        distances: \n",
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = Sample(\n",
    "    cell_types=[1,2,3], \n",
    "    distances=torch.zeros((3,3)), \n",
    "    responder_cell_type=1, \n",
    "    is_dividing=False\n",
    ")\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cellmates.data.dataset.CellMatesDataset at 0x11f9e1be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_dataset_for_n_cells_test()\n",
    "generate_dataset_for_cell_type()\n",
    "generate_dataset_for_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = (3.14*(140**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,L,K = 2,3,4\n",
    "\n",
    "E_HLL = torch.randn((H,L,L))\n",
    "\n",
    "V1_LK = torch.randn((L,K))\n",
    "V2_LK = torch.randn((L,K))\n",
    "\n",
    "V_HLK = torch.stack([V1_LK,V2_LK])\n",
    "\n",
    "# using einsum\n",
    "V_LHK = V_HLK.permute(1,0,2)\n",
    "Z_LHK = torch.einsum(\"HLX,XHK->LHK\", E_HLL, V_LHK)\n",
    "\n",
    "# using straightforward:\n",
    "Z_HLK_sf = torch.matmul(E_HLL, V_HLK)\n",
    "Z_HLK_sf = Z_HLK_sf.view(L,H,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9680, -3.2961, -0.5398,  2.1047],\n",
       "         [ 1.5051,  2.8094, -5.9635, -0.2780]],\n",
       "\n",
       "        [[-2.1689,  2.8505, -0.7173,  1.2626],\n",
       "         [-0.9921, -2.0040,  4.3604,  0.0680]],\n",
       "\n",
       "        [[-2.6026, -1.3980, -0.9697,  2.8767],\n",
       "         [-0.4299,  0.8791, -2.5356,  0.5676]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_LHK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9680, -3.2961, -0.5398,  2.1047],\n",
       "         [-2.1689,  2.8505, -0.7173,  1.2626]],\n",
       "\n",
       "        [[-2.6026, -1.3980, -0.9697,  2.8767],\n",
       "         [ 1.5051,  2.8094, -5.9635, -0.2780]],\n",
       "\n",
       "        [[-0.9921, -2.0040,  4.3604,  0.0680],\n",
       "         [-0.4299,  0.8791, -2.5356,  0.5676]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_HLK_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellmates.model.transformer import SpatialMultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,L,K = 2,3,4\n",
    "D = H*K\n",
    "\n",
    "smh = SpatialMultiHeadAttention(D,H,K,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 16\n",
    "x = torch.randn((B,L,D))\n",
    "smh(x).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
